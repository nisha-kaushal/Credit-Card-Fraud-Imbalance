{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ede8f87",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection with Imbalanced Data: Undersampling vs. Oversampling (Oversampling Notebook)\n",
    "\n",
    "### Goal\n",
    "Credit card fraud detection using labeled data is one of the main basic projects used while learning about data science, machine learning, and binary classifiers. In this notebook, I am less focused on building simple classification models to detect fraud, and instead, I am curious to test the difference between oversampling and undersampling techniques and their outcomes when applied to highly-imbalanced data, like the dataset used here. Utilizing the Imbalanced-Learn library, my goal is to find which of the two sampling techniques is more useful in highly imbalanced data, and how each affects the accuracy.\n",
    "\n",
    "***This project has been broken into 3 notebooks, as one notebook exceeds the file size limit for Github. Also, for sizing purposes, the visualizations have not been outputted. Refer to the README for the visualizations, including any interpretations. These notebooks are for showcasing code only.***\n",
    "\n",
    "### Data Source\n",
    "The original dataset can be found [here](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) <br> \n",
    "**Notes from data source:** \"It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\" <br> \n",
    "\n",
    "In addition, the publisher recommended to not use confusion matrices due to the high imbalance in target variable, however I will utilize them in this notebook because I am comparing methods to create balanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dcc086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e714f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data \n",
    "credit_data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "#credit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2aa4e7",
   "metadata": {},
   "source": [
    "## Predict Fraud\n",
    "### Oversampling vs. Undersampling\n",
    "\n",
    "As seen in the EDA notebook, there is a clear imbalance of classes. There are a few ways imbalance can be handled, and in this notebook I will focus on oversampling (with another notebook focusing on undersampling), and determine which would be more beneficial for the data given.\n",
    "\n",
    "#### Oversampling\n",
    "For Over-sampling, I will use the **Synthetic Minority Oversampling Technique** (SMOTE). Essentially, when applied, SMOTE looks into the k-nearest neighbors of the minority class, and chooses synthetic data based on those neighbors. SMOTE can be applied using the [imblearn library](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html).<br> \n",
    "Steps to implement SMOTE: <br> \n",
    "1. import imblearn.oversampling \n",
    "2. create a SMOTE object, using sampling_strategy = 'minority\" \n",
    "3. fit the object to the data to get oversampled X values and oversampled Y values\n",
    "4. concatenate the oversampled X's and Y's into one dataframe\n",
    "\n",
    "I will use musltiple predictive model algorithms to determine the best model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d72510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568630, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import imblearn \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Resampling the minority class\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "# Fit the model to generate the data.\n",
    "oversampled_X, oversampled_Y = sm.fit_resample(credit_data.drop('Class', axis=1), credit_data['Class'])\n",
    "new_df = pd.concat([pd.DataFrame(oversampled_Y), pd.DataFrame(oversampled_X)], axis=1)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbcf853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284315 non-fraud transactions\n",
      "284315 fraud transactions\n"
     ]
    }
   ],
   "source": [
    "new_fraud = new_df[new_df['Class'] == 1]\n",
    "new_normal = new_df[new_df['Class'] == 0]\n",
    "print(f'{str(len(new_normal))} non-fraud transactions')\n",
    "print(f'{str(len(new_fraud))} fraud transactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce047cd8",
   "metadata": {},
   "source": [
    "Now I can try different classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ed100af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import classification dependencies\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics  import (f1_score,accuracy_score, recall_score, precision_score, confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "408d9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to get X and y using a copy of new_df (assigned to variable ('credit'))\n",
    "credit = new_df.copy()\n",
    "labels = credit['Class']\n",
    "xtrain = credit.drop(['Class'], axis = 1)\n",
    "\n",
    "#To get a validation test set, I will implement train_test_split twice\n",
    "#The beow will give a test set containing 20% of the total data, training set with 60% of the data, and cv set with 20%\n",
    "x_1, X_test, y_1, y_test = train_test_split(xtrain,labels,test_size=0.2,train_size=0.8)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(x_1,y_1,test_size = 0.25,train_size =0.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda66f67",
   "metadata": {},
   "source": [
    "Because I am working with limited computing power, I will leave the below cell's function commented and not utilize it. The below function would conduct all of the desired classification modeling and output a dictionary with the classifier names as the keys, and their corresponding accuracies as the values. If I did utilize it, the run time would be very long, especially for the oversampling portion of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73cc61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classifications(X, y, testsize, max_it, rand_state = 42): \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= testsize, random_state=rand_state)\n",
    "#     l = [ ('Random Forest', RandomForestClassifier(random_state = rand_state)), \n",
    "#          ('Decision Tree', DecisionTreeClassifier(random_state = rand_state)), \n",
    "#          ('Logistic Regression', LogisticRegression(solver='lbfgs', max_iter= max_it, random_state = rand_state)),\n",
    "#         ('K-Nearest Neighbors', KNeighborsClassifier())] \n",
    "#     acc_dict = {}\n",
    "#     for classifier in l: \n",
    "#         c = classifier[1]\n",
    "#         c.fit(X_train, y_train)\n",
    "#         c_pred = c.predict(X_test)\n",
    "#         c_acc = accuracy_score(c_pred, y_test)\n",
    "#         acc_dict[classifier[0]] = c_acc\n",
    "#     return acc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a170a40",
   "metadata": {},
   "source": [
    "First, I will look at **Random Forest**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec04e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997977595272849"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: \n",
    "RAND_STATE = 42\n",
    "\n",
    "rfc = RandomForestClassifier(random_state = RAND_STATE)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "rfc_acc = accuracy_score(rfc_pred, y_test)\n",
    "\n",
    "rfc_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13849bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998768971035648"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is a high accuracy- check out the validation set's accuracy results: \n",
    "y_pred_val_rfc = rfc.predict(X_cv)\n",
    "rfc_cv_acc = accuracy_score(y_cv, y_pred_val_rfc)\n",
    "\n",
    "rfc_cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4046e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Test precision: 0.9996\n",
      "Test precision: 0.9999\n",
      "Validation precision: 0.9998\n",
      "Validation precision: 0.9999\n"
     ]
    }
   ],
   "source": [
    "rfc_test_precision = precision_score(y_test, rfc_pred)\n",
    "rfc_test_recall = recall_score(y_test, rfc_pred)\n",
    "\n",
    "rfc_cv_precision = precision_score(y_cv, y_pred_val_rfc)\n",
    "rfc_cv_recall = recall_score(y_cv, y_pred_val_rfc)\n",
    "\n",
    "print('Random Forest Classifier')\n",
    "print(f'Test precision: {str(round(rfc_test_precision, 4))}')\n",
    "print(f'Test precision: {str(round(rfc_test_recall, 4))}')\n",
    "print(f'Validation precision: {str(round(rfc_cv_precision, 4))}')\n",
    "print(f'Validation precision: {str(round(rfc_cv_recall, 4))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337a347",
   "metadata": {},
   "source": [
    "***For each classifier, I will also create confusion matrices. However, for the sake of file size, I will not output the plots in this notebook. I will only include the code. Please refer to the README for the Confusion Matrices.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix:\n",
    "LABELS = ['Normal', 'Fraud']\n",
    "conf_matrix = confusion_matrix(y_test, rfc_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(conf_matrix, xticklabels = LABELS, yticklabels = LABELS, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74ad45",
   "metadata": {},
   "source": [
    "Next will be **Decision Tree Classifier**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c360a6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9980567328491287"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree:\n",
    "dtc = DecisionTreeClassifier(random_state = RAND_STATE)\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc_pred = dtc.predict(X_test)\n",
    "dtc_acc = accuracy_score(dtc_pred, y_test)\n",
    "\n",
    "dtc_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1502af7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983029386419991"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val_dtc = dtc.predict(X_cv)\n",
    "dtc_cv_acc = accuracy_score(y_cv, y_pred_val_dtc)\n",
    "\n",
    "dtc_cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a310171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Test precision: 0.9974\n",
      "Test precision: 0.9987\n",
      "Validation precision: 0.9977\n",
      "Validation precision: 0.9989\n"
     ]
    }
   ],
   "source": [
    "dtc_test_precision = precision_score(y_test, dtc_pred)\n",
    "dtc_test_recall = recall_score(y_test, dtc_pred)\n",
    "\n",
    "dtc_cv_precision = precision_score(y_cv, y_pred_val_dtc)\n",
    "dtc_cv_recall = recall_score(y_cv, y_pred_val_dtc)\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "print(f'Test precision: {str(round(dtc_test_precision, 4))}')\n",
    "print(f'Test precision: {str(round(dtc_test_recall, 4))}')\n",
    "print(f'Validation precision: {str(round(dtc_cv_precision, 4))}')\n",
    "print(f'Validation precision: {str(round(dtc_cv_recall, 4))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a741db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, dtc_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(conf_matrix, xticklabels = LABELS, yticklabels = LABELS, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a17d9df",
   "metadata": {},
   "source": [
    "**Logistic Regression**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c638b614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971800643652287"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression:\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter= 1000, random_state = RAND_STATE)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_acc = accuracy_score(lr_pred, y_test)\n",
    "\n",
    "lr_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99e1c437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9720292633170955"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val_lr = lr.predict(X_cv)\n",
    "lr_cv_acc = accuracy_score(y_cv, y_pred_val_lr)\n",
    "\n",
    "lr_cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "707264dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Test precision: 0.979\n",
      "Test precision: 0.9642\n",
      "Validation precision: 0.9799\n",
      "Validation precision: 0.9637\n"
     ]
    }
   ],
   "source": [
    "lr_test_precision = precision_score(y_test, lr_pred)\n",
    "lr_test_recall = recall_score(y_test, lr_pred)\n",
    "\n",
    "lr_cv_precision = precision_score(y_cv, y_pred_val_lr)\n",
    "lr_cv_recall = recall_score(y_cv, y_pred_val_lr)\n",
    "\n",
    "print('Logistic Regression')\n",
    "print(f'Test precision: {str(round(lr_test_precision, 4))}')\n",
    "print(f'Test precision: {str(round(lr_test_recall, 4))}')\n",
    "print(f'Validation precision: {str(round(lr_cv_precision, 4))}')\n",
    "print(f'Validation precision: {str(round(lr_cv_recall, 4))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c582ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lr_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(conf_matrix, xticklabels = LABELS, yticklabels = LABELS, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71ce25",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86581e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9538891722209522"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K NEaighbors\n",
    "kn_class = KNeighborsClassifier()\n",
    "kn_class.fit(X_train, y_train)\n",
    "knc_pred = kn_class.predict(X_test) \n",
    "kn_acc = accuracy_score(knc_pred, y_test) \n",
    "kn_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbc0789d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954539858959253"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val_kn = kn_class.predict(X_cv)\n",
    "kn_cv_acc = accuracy_score(y_cv, y_pred_val_kn)\n",
    "\n",
    "kn_cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e2b027d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbor Classifier\n",
      "Test precision: 0.9389\n",
      "Test precision: 0.9708\n",
      "Validation precision: 0.9398\n",
      "Validation precision: 0.9711\n"
     ]
    }
   ],
   "source": [
    "kn_test_precision = precision_score(y_test, knc_pred)\n",
    "kn_test_recall = recall_score(y_test, knc_pred)\n",
    "\n",
    "kn_cv_precision = precision_score(y_cv, y_pred_val_kn)\n",
    "kn_cv_recall = recall_score(y_cv, y_pred_val_kn)\n",
    "\n",
    "print('K-Nearest Neighbor Classifier')\n",
    "print(f'Test precision: {str(round(kn_test_precision, 4))}')\n",
    "print(f'Test precision: {str(round(kn_test_recall, 4))}')\n",
    "print(f'Validation precision: {str(round(kn_cv_precision, 4))}')\n",
    "print(f'Validation precision: {str(round(kn_cv_recall, 4))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, knc_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(conf_matrix, xticklabels = LABELS, yticklabels = LABELS, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c6d851",
   "metadata": {},
   "source": [
    "A detailed overview of the results can be found in the Undersampling notebook (Part 3 of this Project). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8c353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
